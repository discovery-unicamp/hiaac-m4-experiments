{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KuHar Views generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "from librep.datasets.har.kuhar import (\n",
    "    RawKuHar,\n",
    "    RawKuHarIterator,\n",
    "    KuHarDatasetGenerator\n",
    ")\n",
    "from librep.utils.dataset import PandasDatasetsIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"../data/raw/KuHar/1.Raw_time_domian_data\")\n",
    "output_dir = Path(\"../data/processed/KuHar/\")\n",
    "train_size = 0.7\n",
    "validation_size = 0.1\n",
    "test_size = 0.2\n",
    "ensure_distinct_users = True\n",
    "balance_samples = True\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_standard_activity_code(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    labels_map = {\n",
    "        # activity code: standard activity code\n",
    "        0: 1,\n",
    "        1: 0,\n",
    "        2: -1,\n",
    "        3: -1,\n",
    "        4: -1,\n",
    "        5: -1,\n",
    "        6: -1,\n",
    "        7: -1,\n",
    "        8: -1,\n",
    "        9: -1,\n",
    "        10: -1,\n",
    "        11: 2,\n",
    "        12: -1,\n",
    "        13: -1,\n",
    "        14: 5,\n",
    "        15: 3,\n",
    "        16: 4,\n",
    "        17: -1,\n",
    "    }\n",
    "\n",
    "    df[\"standard activity code\"] = df[\"activity code\"].map(labels_map)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuhar_dataset = RawKuHar(dataset_dir, download=False)\n",
    "iterator = RawKuHarIterator(kuhar_dataset)\n",
    "iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [01:25, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbb153e329a602fc5b142f25d6c5da00a35f48d0\n",
      "29a040e169f546975f86585ff1eac437418d611b\n",
      "6e55b90894d73b2f6fc8ff851ff94dc3cb611c65\n",
      "Dataset saved to ../data/processed/KuHar/balanced directory.\n"
     ]
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0, resampler=False, fs=None)\n",
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=train_size,\n",
    "    validation_size=validation_size,\n",
    "    test_size=test_size,\n",
    "    ensure_distinct_users_per_dataset=ensure_distinct_users,\n",
    "    balance_samples=balance_samples,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train, validation, test = list(map(add_standard_activity_code, [train, validation, test]))\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())\n",
    "\n",
    "output_path = output_dir / \"balanced\"\n",
    "\n",
    "description = \"\"\"# Balanced KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples. \n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\"\"\"\n",
    "\n",
    "PandasDatasetsIO(output_path).save(train, validation, test, description=description)\n",
    "print(f\"Dataset saved to {output_path} directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [00:50, 38.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df773b945663a680d6b09d594775e36a5851cf53\n",
      "11168f662309f1d6842e0ef13b766b332ed1fc6e\n",
      "570c2e519e95389c40720df1ce5b5204ba39a845\n",
      "Dataset saved to ../data/processed/KuHar/balanced_normalized directory.\n"
     ]
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=60, window_overlap=0, resampler=True, fs=20)\n",
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=train_size,\n",
    "    validation_size=validation_size,\n",
    "    test_size=test_size,\n",
    "    ensure_distinct_users_per_dataset=ensure_distinct_users,\n",
    "    balance_samples=balance_samples,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train, validation, test = list(map(add_standard_activity_code, [train, validation, test]))\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())\n",
    "\n",
    "output_path = output_dir / \"balanced_normalized\"\n",
    "\n",
    "description = \"\"\"# Balanced Normalized KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples. \n",
    "The samples were resampled to 20Hz before splitting into windows.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\"\"\"\n",
    "\n",
    "PandasDatasetsIO(output_path).save(train, validation, test, description=description)\n",
    "print(f\"Dataset saved to {output_path} directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Data\n",
    "\n",
    "Here we include only selected activities: 0, 1, 11, 14, 15, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_activities = [0, 1, 11, 14, 15, 16]\n",
    "iterator = RawKuHarIterator(kuhar_dataset, activities=selected_activities)\n",
    "iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 625it [00:28, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24d9a14deb7c24a736d052aa6349adfab061dac6\n",
      "70dd040328487caaef43a1ca5772133c8c68a18a\n",
      "01bc6661dedeed42dbfa1bfa455b33cbeab27ceb\n",
      "Dataset saved to ../data/processed/KuHar/selected_balanced directory.\n"
     ]
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0, resampler=False, fs=None)\n",
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=train_size,\n",
    "    validation_size=validation_size,\n",
    "    test_size=test_size,\n",
    "    ensure_distinct_users_per_dataset=ensure_distinct_users,\n",
    "    balance_samples=balance_samples,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train, validation, test = list(map(add_standard_activity_code, [train, validation, test]))\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())\n",
    "\n",
    "output_path = output_dir / \"selected_balanced\"\n",
    "\n",
    "description = \"\"\"# Selected Balanced KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples. \n",
    "Only standard activities were selected, that is, activities 0, 1, 11, 14, 15 and 16.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\"\"\"\n",
    "\n",
    "PandasDatasetsIO(output_path).save(train, validation, test, description=description)\n",
    "print(f\"Dataset saved to {output_path} directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 625it [00:16, 38.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c7a474c9b374606034d4f7787301d78daf8f2d5c\n",
      "f89cc1a8be4ee1598cfa04f8b94f931efddc55b9\n",
      "e12611033c2c99739a8ef1a3071f1a885ed70196\n",
      "Dataset saved to ../data/processed/KuHar/selected_balanced_normalized directory.\n"
     ]
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=60, window_overlap=0, resampler=True, fs=20)\n",
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=train_size,\n",
    "    validation_size=validation_size,\n",
    "    test_size=test_size,\n",
    "    ensure_distinct_users_per_dataset=ensure_distinct_users,\n",
    "    balance_samples=balance_samples,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train, validation, test = list(map(add_standard_activity_code, [train, validation, test]))\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())\n",
    "\n",
    "output_path = output_dir / \"selected_balanced_normalized\"\n",
    "\n",
    "description = \"\"\"# Balanced Normalized KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples. \n",
    "The samples were resampled to 20Hz before splitting into windows. Only standard activities were selected, that is, activities 0, 1, 11, 14, 15 and 16.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\"\"\"\n",
    "\n",
    "PandasDatasetsIO(output_path).save(train, validation, test, description=description)\n",
    "print(f\"Dataset saved to {output_path} directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".librep-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e57cbd9857f73b6186314efc0497b85fc81e429910d4dfbf03f56c852bfb6a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
