{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea402ac5-031d-4b8a-b330-b71f2085f956",
   "metadata": {},
   "source": [
    "# Pre-processing MotionSense Dataset and Generate Views - Without Gravity - Filtered - Multiplying Acc by 9.81 m/sÂ² - Resampling to 20 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498254b0-ea10-4f02-b718-d26ce855b77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad53baa-1190-4969-9ae9-489321c5966e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "from librep.datasets.har.motionsense import (\n",
    "    RawMotionSense,\n",
    "    RawMotionSenseIterator,\n",
    "    MotionSenseDatasetGenerator\n",
    ")\n",
    "from librep.utils.dataset import PandasDatasetsIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cf88f",
   "metadata": {},
   "source": [
    "## Raw balanced MotionSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bf855c-9947-4174-980c-5942527eaf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MotionSense Dataset at: '../../data_2/views/MotionSense/A_DeviceMotion_data/A_DeviceMotion_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = Path(\"../../data_2/views/MotionSense/A_DeviceMotion_data/A_DeviceMotion_data\")\n",
    "motionsense_dataset = RawMotionSense(dataset_dir, download=False)\n",
    "motionsense_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c2abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_names = [motionsense_dataset.activity_names[i] for i in motionsense_dataset.activities]\n",
    "act_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ffda3f-7686-49d1-a02d-576e4207b6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MotionSense Iterator: users=0, activities=0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = RawMotionSenseIterator(motionsense_dataset, users_to_select=None, activities_to_select=None)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75a8cb6-5083-44f9-bfbd-50f55836bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset generator: time_window=150, overlap=0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motionsense_raw = MotionSenseDatasetGenerator(iterator, time_window=150, window_overlap=0, add_gravity=False, \n",
    "                                             add_filter=False, resampler=False, change_acc_measure=False)\n",
    "\n",
    "\n",
    "motionsense_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add044d7-6666-4f31-93e5-d4af57e01e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over MotionSense View: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, validation, test \u001b[38;5;241m=\u001b[39m \u001b[43mmotionsense_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_distinct_users_per_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbalance_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(hashlib\u001b[38;5;241m.\u001b[39msha1(pd\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mhash_pandas_object(train)\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mhexdigest())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(hashlib\u001b[38;5;241m.\u001b[39msha1(pd\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mhash_pandas_object(validation)\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mhexdigest())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librep/datasets/har/motionsense.py:630\u001b[0m, in \u001b[0;36mMotionSenseDatasetGenerator.create_datasets\u001b[0;34m(self, train_size, validation_size, test_size, ensure_distinct_users_per_dataset, balance_samples, activities_remap, seed, use_tqdm)\u001b[0m\n\u001b[1;32m    627\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m    628\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m--> 630\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_full_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m users \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librep/datasets/har/motionsense.py:507\u001b[0m, in \u001b[0;36mMotionSenseDatasetGenerator.get_full_df\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(it)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__create_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "train, validation, test = motionsense_raw.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    seed=0\n",
    ")\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14626daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "motionsense_v2 = MotionSenseDatasetGenerator(iterator, time_window=60, window_overlap=0, add_gravity=True, \n",
    "add_filter=True, resampler=True, fs=20, change_acc_measure=True)\n",
    "\n",
    "motionsense_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2, validation_v2, test_v2 = motionsense_v2.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    seed=0\n",
    ")\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(train_v2).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation_v2).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test_v2).values).hexdigest())\n",
    "\n",
    "print(sorted(train_v2['user'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5808845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.all(train_v2['index']/20 == train['index']/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import fftpack\n",
    "\n",
    "ind = 10\n",
    "\n",
    "cols = [f\"userAcceleration.{axis}-{i}\" for axis in [\"x\"] for i in range(150)]\n",
    "sample_raw = train[cols].iloc[ind].values\n",
    "\n",
    "data_raw = fftpack.fft(sample_raw)\n",
    "data_raw = np.abs(data_raw)\n",
    "\n",
    "cols = [f\"userAcceleration.{axis}-{i}\" for axis in [\"x\"] for i in range(60)]\n",
    "sample_norm = train_v2[cols].iloc[ind].values\n",
    "\n",
    "data_norm = fftpack.fft(sample_norm)\n",
    "data_norm = np.abs(data_norm)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(np.arange(30), data_raw[:30], label = 'Raw')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(np.arange(30), data_norm[:30], label = 'Norm', color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcb11-f07e-4e60-a859-ea209900beb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())\n",
    "\n",
    "# 3d2e3d49233efdc3dfc138e55b2d44a51cf80c9d\n",
    "# ece6166a183c151a9ac1a3111d300891f2fe1db8\n",
    "# 9a7f20e984b305059b737e8f72cbd0e246345980\n",
    "\n",
    "# 49bf80a87770414b49273263820f63f3c0e816c8\n",
    "# e9f2ec9067ff9f85add9fbbc03fabff34a6b2deb\n",
    "# 70168e3ac19682d6c21757dd9b25ca48dd956298\n",
    "\n",
    "# seed = 42\n",
    "# 52e16cbcf555433634ea7b255caa4769f94f53ad\n",
    "# b8d9b33b2b0c1e5b45ef10d87cacf2515c742dd2\n",
    "# 1db66b9ee2285a1a6232f79c9dc20b9422fd5230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9cda8-f111-4715-94c2-e474574149ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = Path(\"../../data_2/views/MotionSense/balanced_view_20Hz_filtered_9.81_acc\")\n",
    "\n",
    "description = \"\"\"# Balanced MotionSense\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\"\"\"\n",
    "pandas_io = PandasDatasetsIO(output_path)\n",
    "pandas_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a9c1b-beca-4c22-a84a-319fc341e709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(\n",
    "    train=train, \n",
    "    validation=validation, \n",
    "    test=test, \n",
    "    description=description\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e726e1b",
   "metadata": {},
   "source": [
    "## Normalized balanced MotionSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af607b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
